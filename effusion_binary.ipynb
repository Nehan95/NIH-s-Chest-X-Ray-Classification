{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/kaggle/working'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, average_precision_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/kaggle/input/data/'\n",
    "image_size = 256\n",
    "batch_size = 32\n",
    "os.chdir(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_Entry_2017.csv')\n",
    "os.chdir('/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/kaggle/input/data/images_001/images/00000001_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/kaggle/input/data/images_001/images/00000001_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/kaggle/input/data/images_001/images/00000001_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/kaggle/input/data/images_001/images/00000002_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/kaggle/input/data/images_001/images/00000003_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  \\\n",
       "0                        0.143  0.143          NaN   \n",
       "1                        0.143  0.143          NaN   \n",
       "2                        0.168  0.168          NaN   \n",
       "3                        0.171  0.171          NaN   \n",
       "4                        0.143  0.143          NaN   \n",
       "\n",
       "                                                path  \n",
       "0  /kaggle/input/data/images_001/images/00000001_...  \n",
       "1  /kaggle/input/data/images_001/images/00000001_...  \n",
       "2  /kaggle/input/data/images_001/images/00000001_...  \n",
       "3  /kaggle/input/data/images_001/images/00000002_...  \n",
       "4  /kaggle/input/data/images_001/images/00000003_...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_image_paths = {os.path.basename(x): x for x in glob(os.path.join(data_directory, 'images*', '*', '*.png'))}\n",
    "df['path'] = df['Image Index'].map(data_image_paths.get)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating labels for binary classificatiion\n",
    "l=[]\n",
    "for i in list(df['Finding Labels']):\n",
    "    if i=='Effusion':\n",
    "        l.append('Present')\n",
    "    else:\n",
    "        l.append('Absent')\n",
    "df['labels']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['Absent','Present']\n",
    "df['Absent']=list(map((lambda x: 1.0 if x=='False' else 0.0),list(df['labels'])))\n",
    "df['Present']=list(map((lambda x: 0.0 if x=='False' else 1.0),list(df['labels'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing normal/NO-Finding labelled images and Hernia Images\n",
    "df=df.drop(df[df['Finding Labels']=='No Finding'].index,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating more balanced dataset\n",
    "df1=df.drop(df[df['labels']=='False'].index,axis=0)\n",
    "df1=df1.reset_index()\n",
    "df2=df.drop(df[df['labels']=='True'].index,axis=0)\n",
    "df2=df2.reset_index()\n",
    "df2=df2.drop('index',axis=1)\n",
    "\n",
    "df3=df2[df2.index<4000]\n",
    "df=pd.concat([df1, df3], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df=df.drop(['index'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(df, test_size=0.20, random_state=2018,stratify=df['labels'].map(lambda x: x[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44607 validated image filenames belonging to 2 classes.\n",
      "Found 11152 validated image filenames belonging to 2 classes.\n",
      "Found 11152 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "core_idg = ImageDataGenerator(rescale=1 / 255,\n",
    "                                  samplewise_center=True,\n",
    "                                  samplewise_std_normalization=True,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=False,\n",
    "                                  height_shift_range=0.05,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  rotation_range=5,\n",
    "                                  shear_range=0.1,\n",
    "                                  fill_mode='reflect',\n",
    "                                  zoom_range=0.15)\n",
    "\n",
    "train_gen = core_idg.flow_from_dataframe(dataframe=train_df,\n",
    "                                             directory=None,\n",
    "                                             x_col='path',\n",
    "                                             y_col='labels',\n",
    "                                             class_mode='categorical',\n",
    "                                             batch_size=batch_size,\n",
    "                                             classes=labels,\n",
    "                                             target_size=(image_size, image_size))\n",
    "\n",
    "valid_gen = core_idg.flow_from_dataframe(dataframe=valid_df,\n",
    "                                             directory=None,\n",
    "                                             x_col='path',\n",
    "                                             y_col='labels',\n",
    "                                             class_mode='categorical',\n",
    "                                             batch_size=batch_size,\n",
    "                                             classes=labels,\n",
    "                                             target_size=(image_size, image_size))\n",
    "\n",
    "test_X, test_Y = next(core_idg.flow_from_dataframe(dataframe=valid_df,\n",
    "                                                       directory=None,\n",
    "                                                       x_col='path',\n",
    "                                                       y_col='labels',\n",
    "                                                       class_mode='categorical',\n",
    "                                                       batch_size=1024,\n",
    "                                                       classes=labels,\n",
    "                                                       target_size=(image_size, image_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "base_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(len(labels), activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(base_model.input, output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    callbacks = []\n",
    "    tensor_board = tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0)\n",
    "    callbacks.append(tensor_board)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'{model_name}.h5',\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "    callbacks.append(checkpoint)\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps, validate on 1024 samples\n",
      "Epoch 1/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.3479 - accuracy: 0.9042\n",
      "Epoch 00001: val_loss improved from inf to 10.47966, saving model to multi_class.h5\n",
      "100/100 [==============================] - 159s 2s/step - loss: 0.3469 - accuracy: 0.9045 - val_loss: 10.4797 - val_accuracy: 0.9199\n",
      "Epoch 2/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2578 - accuracy: 0.9283\n",
      "Epoch 00002: val_loss improved from 10.47966 to 5.03630, saving model to multi_class.h5\n",
      "100/100 [==============================] - 131s 1s/step - loss: 0.2580 - accuracy: 0.9281 - val_loss: 5.0363 - val_accuracy: 0.9199\n",
      "Epoch 3/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2728 - accuracy: 0.9208\n",
      "Epoch 00003: val_loss improved from 5.03630 to 0.30306, saving model to multi_class.h5\n",
      "100/100 [==============================] - 128s 1s/step - loss: 0.2740 - accuracy: 0.9200 - val_loss: 0.3031 - val_accuracy: 0.9199\n",
      "Epoch 4/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2687 - accuracy: 0.9261\n",
      "Epoch 00004: val_loss did not improve from 0.30306\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.2681 - accuracy: 0.9266 - val_loss: 0.9533 - val_accuracy: 0.9199\n",
      "Epoch 5/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2458 - accuracy: 0.9306\n",
      "Epoch 00005: val_loss improved from 0.30306 to 0.27008, saving model to multi_class.h5\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.2471 - accuracy: 0.9306 - val_loss: 0.2701 - val_accuracy: 0.9199\n",
      "Epoch 6/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2589 - accuracy: 0.9268\n",
      "Epoch 00006: val_loss improved from 0.27008 to 0.26353, saving model to multi_class.h5\n",
      "100/100 [==============================] - 128s 1s/step - loss: 0.2578 - accuracy: 0.9272 - val_loss: 0.2635 - val_accuracy: 0.9199\n",
      "Epoch 7/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2663 - accuracy: 0.9208\n",
      "Epoch 00007: val_loss did not improve from 0.26353\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.2653 - accuracy: 0.9209 - val_loss: 0.2907 - val_accuracy: 0.9199\n",
      "Epoch 8/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2551 - accuracy: 0.9252\n",
      "Epoch 00008: val_loss did not improve from 0.26353\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.2570 - accuracy: 0.9247 - val_loss: 0.4659 - val_accuracy: 0.9199\n",
      "Epoch 9/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2391 - accuracy: 0.9350\n",
      "Epoch 00009: val_loss did not improve from 0.26353\n",
      "100/100 [==============================] - 123s 1s/step - loss: 0.2382 - accuracy: 0.9350 - val_loss: 0.3109 - val_accuracy: 0.9199\n",
      "Epoch 10/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2486 - accuracy: 0.9236\n",
      "Epoch 00010: val_loss did not improve from 0.26353\n",
      "100/100 [==============================] - 123s 1s/step - loss: 0.2489 - accuracy: 0.9237 - val_loss: 0.2774 - val_accuracy: 0.9199\n",
      "Epoch 11/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2584 - accuracy: 0.9239\n",
      "Epoch 00011: val_loss did not improve from 0.26353\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.2579 - accuracy: 0.9240 - val_loss: 0.3651 - val_accuracy: 0.9199\n",
      "Epoch 12/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2487 - accuracy: 0.9249\n",
      "Epoch 00012: val_loss improved from 0.26353 to 0.26123, saving model to multi_class.h5\n",
      "100/100 [==============================] - 125s 1s/step - loss: 0.2507 - accuracy: 0.9244 - val_loss: 0.2612 - val_accuracy: 0.9199\n",
      "Epoch 13/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2642 - accuracy: 0.9198\n",
      "Epoch 00013: val_loss did not improve from 0.26123\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.2632 - accuracy: 0.9200 - val_loss: 0.3105 - val_accuracy: 0.9199\n",
      "Epoch 14/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2598 - accuracy: 0.9189\n",
      "Epoch 00014: val_loss did not improve from 0.26123\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.2601 - accuracy: 0.9187 - val_loss: 0.2904 - val_accuracy: 0.9199\n",
      "Epoch 15/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2387 - accuracy: 0.9293\n",
      "Epoch 00015: val_loss did not improve from 0.26123\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.2406 - accuracy: 0.9287 - val_loss: 0.3147 - val_accuracy: 0.9199\n",
      "Epoch 16/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2686 - accuracy: 0.9160\n",
      "Epoch 00016: val_loss improved from 0.26123 to 0.26100, saving model to multi_class.h5\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.2672 - accuracy: 0.9166 - val_loss: 0.2610 - val_accuracy: 0.9199\n",
      "Epoch 17/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2597 - accuracy: 0.9189\n",
      "Epoch 00017: val_loss did not improve from 0.26100\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.2588 - accuracy: 0.9194 - val_loss: 0.2884 - val_accuracy: 0.9199\n",
      "Epoch 18/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2511 - accuracy: 0.9261\n",
      "Epoch 00018: val_loss did not improve from 0.26100\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.2504 - accuracy: 0.9266 - val_loss: 0.4007 - val_accuracy: 0.9199\n",
      "Epoch 19/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2588 - accuracy: 0.9195\n",
      "Epoch 00019: val_loss did not improve from 0.26100\n",
      "100/100 [==============================] - 121s 1s/step - loss: 0.2588 - accuracy: 0.9194 - val_loss: 0.3042 - val_accuracy: 0.9199\n",
      "Epoch 20/20\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2506 - accuracy: 0.9280\n",
      "Epoch 00020: val_loss did not improve from 0.26100\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.2514 - accuracy: 0.9278 - val_loss: 0.3215 - val_accuracy: 0.9199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8db6ec5c90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = get_callbacks('multi_class')\n",
    "model.fit(train_gen,\n",
    "              steps_per_epoch=100,\n",
    "              validation_data=(test_X, test_Y),\n",
    "              epochs=20,\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_X)\n",
    "predicted = [np.argmax(i) for i in y_pred]\n",
    "actual=[np.argmax(i) for i in test_Y]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
